---
title: Use a Custom WeightInfo trait from benchmarking
slug: /how-to-guides/v3/weights/use-benchmark-weights
keywords: weights, benchmarking, runtime
version: 3.0 
section: how to guides
category: weights
difficulty: 1
---

<Objectives
  data={[
    {
      title: 'Goal',
      description: 'Add FRAME\'s benchmarking tool to your pallet and write a simple benchmark.',
    },
    {
      title: 'Use Cases',
      description:
        `Configuring accurate weights for a pallet's extrinsics`,
    },
    {
      title: 'Overview',
      description:
        `This guides steps throught the process of adding benchmarking to a pallet and runtime. In addition, 
        it covers the steps of writing a simple benchmark for a pallet as well as testing and running the 
        benchmarking tool. This guide does not cover updating weights with benchmarked values.`,
    },
  ]}
/>

## Steps

### Set-up benchmarking for your pallet

### Analyzing and Outputting Your Benchmarks

After running the `benchmark` command above, we have two outputs. The raw data with benchmarked time
and the auto-generated Rust file of `WeightInfo` implementation.

#### Raw Data

The first output is the raw data recording how much time is spent on running the execution state
when varying the input variables. At the end for each variable, the coefficient, assuming linear
relationship, between the execution time with respect to change in the variable is determined.

This is a snippet of the output:

```csv
Pallet: "pallet_example", Extrinsic: "accumulate_dummy", Lowest values: [], Highest values: [], Steps: [10], Repeat: 5
b,extrinsic_time,storage_root_time,reads,repeat_reads,writes,repeat_writes
1,1231926,162640,1,4,1,2
1,1245146,128021,1,4,1,2
1,1238746,126051,1,4,1,2
1,1206004,126391,1,4,1,2
1,1212564,127941,1,4,1,2
100,1257646,129750,1,4,1,2
100,1232476,125780,1,4,1,2
100,1215466,128310,1,4,1,2
100,1205835,129070,1,4,1,2
...
991,1208294,125820,1,4,1,2
991,1209305,126921,1,4,1,2
991,1203275,125031,1,4,1,2
991,1234855,124190,1,4,1,2
991,1337136,125060,1,4,1,2

Median Slopes Analysis
========
-- Extrinsic Time --

Model:
Time ~=     1231
    + b        0
              µs

Reads = 1 + (0 * b)
Writes = 1 + (0 * b)

Min Squares Analysis
========
-- Extrinsic Time --

Data points distribution:
    b   mean µs  sigma µs       %
    1      1230     12.61    1.0%
  100      1230     16.53    1.3%
  199      1227     12.88    1.0%
  298      1215     12.94    1.0%
  397      1239     19.83    1.6%
  496      1234     18.51    1.5%
  595      1228     7.167    0.5%
  694      1233     13.51    1.0%
  793      1218     9.876    0.8%
  892      1225     14.15    1.1%
  991      1220     11.63    0.9%

Quality and confidence:
param     error
b         0.006

Model:
Time ~=     1230
    + b        0
              µs

Reads = 1 + (0 * b)
Writes = 1 + (0 * b)
```

With the median slopes analysis, this is the weight function:

```
1231 µs + (0 * b) +
  [1 + (0 * b)] * db read time +
  [1 + (0 * b)] * db write time
```

We separate the db/storage read and write out because they are particularly expensive and their
respective operation time will be retrieved from the runtime. We just need to measure how many db
read write are performed with respect to the change of `b`.

The benchmark result is telling us that it will always perform 1 db read and 1 db write no matter
how `b` changes.

The benchmark library gives us both a median slope analysis; that the execution time of a particular
`b` value is taken as the median value of the repeated runs, and a [min. square
analysis](https://en.wikipedia.org/wiki/Least_squares) that is better explained in a statistics
primer.

You can also derive your own coefficients given you have the raw data on each run, say maybe you
know the computation time will not be a linear but an _O(nlogn)_ relationship with the input
variable. So you need to determine the coefficient differently.

### Auto-generated `WeightInfo` Implementation

The second output is an auto-generated `WeightInfo` implementation. This file defines weight
functions of benchmarked extrinsics with the computed coefficient above. We can directly integrated
this file in your pallet or further customize them if so desired. The auto-generated implementation
is designed to make end-to-end weight updates easy.

To use this file, we first define a `WeightInfo` trait in
[`frame/example/src/lib.rs`](https://github.com/paritytech/substrate/blob/master/frame/example/src/lib.rs):

```rust
pub trait WeightInfo {
  fn accumulate_dummy(b: u32, ) -> Weight;
  fn set_dummy(b: u32, ) -> Weight;
  fn sort_vector(x: u32, ) -> Weight;
}
```

Here, associated function `set_dummy` take a parameter. This is because we have the line `let b in 1 .. 1000;` 
in our `set_dummy` benchmarking function, indicating the execution time likely be affected by this parameter.

The generated file implements these associated functions. To integrate them, we can copy the
generated file into the directory where `lib.rs` is located and named it as `weights.rs`.

In the `frame/example/src/lib.rs`, we have:

```rust
// importing the `weights.rs` here
pub mod weights;

pub mod pallet {
  // -- snip --
  #[pallet::call]
  impl<T: Config> Pallet<T> {
    #[pallet::weight(
      T::WeightInfo::set_dummy((*new_value).saturated_into())
    )]
    pub(super) fn set_dummy(
      origin: OriginFor<T>,
      #[pallet::compact] new_value: T::Balance,
    ) -> DispatchResult {
      // -- snip
      Ok(())
    }
  }
}
```

For each extrinsic, we add an attribute `#[pallet::weight]` and pass in the weight implementation
function with the same name as the extrinsic and variables that affect the weight. We can pass
extrinsic parameters as weight function inputs to estimate the final weight.
